services:
  llama-service:
    build:
      context: .
      dockerfile: Dockerfile.llama
    ports:
      - "11434:11434"
    container_name: llama-container

  embed-service:
    build:
      context: .
      dockerfile: Dockerfile.embed
    ports:
      - "11435:11434"
    container_name: embed-container

  app:
    build:
      context: .
      dockerfile: Dockerfile.app
    depends_on:
      - llama-service
      - embed-service
    environment:
      - OLLAMA_HOST=llama-service
      - EMBEDDER_HOST=embed-service
    stdin_open: true
    tty: true
    container_name: agentqa-app
